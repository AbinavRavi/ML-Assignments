
\documentclass[5pt,a4paper]{article}
\usepackage{geometry}
\geometry{
	a4paper,
	total={170mm,257mm},
	left=20mm,
	top=20mm,
}
\usepackage[latin1]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\begin{document}
	\title{Machine learning Homework- Deep Learning }
	\author{Abinav Ravi Venkatakrishnan - 03694216 and Abhijeet Parida - 03679676}
	\maketitle
	\section{Activation Function}
	\subsection*{Problem 1:}
	
	
	\section*{Problem 2:}
	
	
	\section*{Problem 3:}
	
	
	\section*{Problem 4:}
	
	\section*{Problem 5:}
	\begin{enumerate}
		\item from $g(\alpha)$ we know that $\alpha Q\alpha^T$ is equivalent to $-\sum_{i=1}^{N}\sum_{j=1}^{N} y_i y_j \alpha_i \alpha_j \textbf{x}_i \textbf{x}_j$. By rearranging the scalars we get,$-\sum_{i=1}^{N}\sum_{j=1}^{N}\alpha_i  y_i y_j  \textbf{x}_i \textbf{x}_j \alpha_j$. \\Therefore $Q= (-yy^T(hadamard)XX^T)$		\item We know that $Q=-p^Tp$ and also we know that $p^Tp$ is positive semi definite due to its symmetric nature. So $a^t (p^Tp)a \geq 0$ but we negative sign also. Therefore, $Q$ is negative semi definite.
		\item The negative semi definiteness allows the concave optimisation to be a maximisation problem. 
	\end{enumerate}
	
\end{document}